{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J1IDBOPhhycm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(666)\n",
        "\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow import keras\n",
        "import os, shutil\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLjS44gjLDBv",
        "outputId": "8ba2486a-b447-4548-bfe1-a25fe0d88168"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "d98HMfimJ0Fc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AyJAskIWn3yf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d744348-d9b1-4c8a-b00a-9f930d2475c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BXdKHpT9n3vs"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/data/'\n",
        "\n",
        "train_dir = data_path + 'train'\n",
        "val_dir = data_path + 'val'\n",
        "test_dir = data_path + 'test'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 224\n",
        "img_width = 224\n",
        "img_depth = 3\n",
        "img_size = (img_height, img_width)\n",
        "batch_size = 50\n",
        "EPOCHS = 15\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n"
      ],
      "metadata": {
        "id": "qZ26RLCsALIB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = (\n",
        "    tf.keras.utils.image_dataset_from_directory(\n",
        "                  train_dir,\n",
        "                  seed=123,\n",
        "                  image_size=(img_height, img_width),\n",
        "                  batch_size=batch_size)\n",
        "                  .shuffle(100)\n",
        "                  .prefetch(AUTO))\n",
        "\n",
        "val_dataset = (\n",
        "    tf.keras.utils.image_dataset_from_directory(\n",
        "                  val_dir,\n",
        "                  seed=123,\n",
        "                  image_size=(img_height, img_width),\n",
        "                  batch_size=batch_size)\n",
        "                  .shuffle(100)\n",
        "                  .prefetch(AUTO))\n",
        "\n",
        "test_dataset = (\n",
        "    tf.keras.utils.image_dataset_from_directory(\n",
        "        test_dir,\n",
        "        seed=123,\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzMCVExi94Su",
        "outputId": "822b6c4b-45c6-4101-987a-31a493b08c0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5599 files belonging to 8 classes.\n",
            "Found 1600 files belonging to 8 classes.\n",
            "Found 800 files belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch = 50\n",
        "\n",
        "train_datagen = ImageDataGenerator()\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)\n",
        "label_map = (train_generator.class_indices)\n",
        "\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n",
        "label_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joDr7mCY6pkQ",
        "outputId": "b6f9e208-adf8-4625-9390-aa841237089e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5599 images belonging to 8 classes.\n",
            "Found 1600 images belonging to 8 classes.\n",
            "Found 800 images belonging to 8 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Засветы': 0,\n",
              " 'Малая часть упаковки видна на фото': 1,\n",
              " 'Не читабилен текст': 2,\n",
              " 'Нормальные': 3,\n",
              " 'Размытые': 4,\n",
              " 'Фото не в том режиме': 5,\n",
              " 'Фото полки где 4-5 товара и видно что фоткали не основ товар': 6,\n",
              " 'Фото ценника': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teacher model utility\n",
        "base_model = load_model('/content/drive/MyDrive/dataset/ENetB4new25.h5')\n",
        "\n",
        "\n",
        "def get_teacher_model():\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    classifier = models.Model(inputs=inputs, outputs=x)\n",
        "    \n",
        "    return classifier"
      ],
      "metadata": {
        "id": "i1WhMp0M2VKJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_teacher_model().summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRwd4cVj2VM1",
        "outputId": "e4b92279-e9de-4615-93fd-fb9549842f0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 8)                 107598439 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 107,598,439\n",
            "Trainable params: 89,924,616\n",
            "Non-trainable params: 17,673,823\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the teacher model\n",
        "teacher_model = get_teacher_model()\n",
        "teacher_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-4), metrics=[\"accuracy\"])\n",
        "# teacher_model.fit(train_generator,\n",
        "#                   validation_data=val_generator,\n",
        "#                   epochs=1)"
      ],
      "metadata": {
        "id": "1VsK9t7t2VPX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model.evaluate(test_generator)\n",
        "teacher_model.save_weights(\"/content/drive/MyDrive/dataset/teacher_model1.h5\")\n",
        "teacher_model.save_weights(\"teacher_model1.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfEhm--I2VR4",
        "outputId": "414e380b-1ee9-4e60-b56c-ac1db00c913a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 253s 16s/step - loss: 0.2935 - accuracy: 0.9475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = student\n",
        "        self.student = teacher\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        \"\"\" Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "            )\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results"
      ],
      "metadata": {
        "id": "CJxfAUoB0CTI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout,Flatten,\\\n",
        "                                    Dense, Activation, GlobalAveragePooling2D, BatchNormalization,\\\n",
        "                                    AveragePooling2D, Concatenate, Activation\n",
        "from tensorflow.keras.applications import mobilenet, densenet\n",
        "from tensorflow.keras.models import load_model, Model, clone_model"
      ],
      "metadata": {
        "id": "s9A1245ev_XW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(224, 224, 3)),\n",
        "        layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(8),\n",
        "    ],\n",
        "    name=\"student\",\n",
        ")\n",
        "# Clone student for later comparison\n",
        "student_scratch = keras.models.clone_model(student_model)"
      ],
      "metadata": {
        "id": "FEbCCljE5orn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and compile distiller\n",
        "distiller = Distiller(student=student_model, teacher=teacher_model)\n",
        "distiller.compile(\n",
        "    optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=10,\n",
        ")\n",
        "\n",
        "# Distill teacher to student\n",
        "distiller.fit(train_dataset, epochs=3)\n",
        "\n",
        "# Evaluate student on test dataset\n",
        "distiller.evaluate(test_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGqyh8Oocgaf",
        "outputId": "09b2a331-4307-4d56-9d90-6981283b39e5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/112 [==============================] - 882s 522ms/step - sparse_categorical_accuracy: 0.9905 - student_loss: 0.0379 - distillation_loss: 1.9664\n",
            "Epoch 2/3\n",
            "112/112 [==============================] - 90s 276ms/step - sparse_categorical_accuracy: 0.9968 - student_loss: 0.0119 - distillation_loss: 1.9672\n",
            "Epoch 3/3\n",
            "112/112 [==============================] - 88s 270ms/step - sparse_categorical_accuracy: 0.9979 - student_loss: 0.0187 - distillation_loss: 1.9665\n",
            "16/16 [==============================] - 15s 466ms/step - sparse_categorical_accuracy: 0.9513 - student_loss: 0.2911\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9512500166893005, 0.09022154659032822]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AOh8j-NO6DLm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_scratch.compile(\n",
        "    optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "# Train and evaluate student trained from scratch.\n",
        "student_scratch.fit(train_dataset, epochs=15)\n"
      ],
      "metadata": {
        "id": "9ARi1rJEcgdP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4269350-4c1c-4380-c0bf-13a58532a236"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "112/112 [==============================] - 64s 39ms/step - loss: 111.1186 - sparse_categorical_accuracy: 0.4460\n",
            "Epoch 2/15\n",
            "112/112 [==============================] - 62s 42ms/step - loss: 6.2470 - sparse_categorical_accuracy: 0.8059\n",
            "Epoch 3/15\n",
            "112/112 [==============================] - 68s 56ms/step - loss: 1.6853 - sparse_categorical_accuracy: 0.9139\n",
            "Epoch 4/15\n",
            "112/112 [==============================] - 62s 42ms/step - loss: 0.7875 - sparse_categorical_accuracy: 0.9557\n",
            "Epoch 5/15\n",
            "112/112 [==============================] - 62s 42ms/step - loss: 0.3439 - sparse_categorical_accuracy: 0.9711\n",
            "Epoch 6/15\n",
            "112/112 [==============================] - 64s 42ms/step - loss: 0.3021 - sparse_categorical_accuracy: 0.9787\n",
            "Epoch 7/15\n",
            "112/112 [==============================] - 62s 42ms/step - loss: 0.1907 - sparse_categorical_accuracy: 0.9852\n",
            "Epoch 8/15\n",
            "112/112 [==============================] - 62s 42ms/step - loss: 0.1416 - sparse_categorical_accuracy: 0.9877\n",
            "Epoch 9/15\n",
            "112/112 [==============================] - 64s 45ms/step - loss: 0.1397 - sparse_categorical_accuracy: 0.9886\n",
            "Epoch 10/15\n",
            "112/112 [==============================] - 64s 43ms/step - loss: 0.1800 - sparse_categorical_accuracy: 0.9871\n",
            "Epoch 11/15\n",
            "112/112 [==============================] - 62s 42ms/step - loss: 0.1030 - sparse_categorical_accuracy: 0.9921\n",
            "Epoch 12/15\n",
            "112/112 [==============================] - 63s 55ms/step - loss: 0.0827 - sparse_categorical_accuracy: 0.9934\n",
            "Epoch 13/15\n",
            "112/112 [==============================] - 62s 42ms/step - loss: 0.0920 - sparse_categorical_accuracy: 0.9932\n",
            "Epoch 14/15\n",
            "112/112 [==============================] - 62s 42ms/step - loss: 0.0694 - sparse_categorical_accuracy: 0.9952\n",
            "Epoch 15/15\n",
            "112/112 [==============================] - 64s 42ms/step - loss: 0.0379 - sparse_categorical_accuracy: 0.9966\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe1d5aa5050>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_scratch.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "PwNqGNDPcggG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6106792a-efb7-42a4-bc54-ce20f3fd930c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 10s 262ms/step - loss: 2.8466 - sparse_categorical_accuracy: 0.9488\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.8465735912323, 0.9487500190734863]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "k4_Q8HqbkeSa"
      },
      "outputs": [],
      "source": [
        "student_scratch.save_weights(\"/content/drive/MyDrive/dataset/student_model1.h5\")\n",
        "student_scratch.save_weights(\"student_model1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AH-77R1RkeP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31fc03f8-ef65-4c76-ec10-b16df581956f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 3.1M Nov 19 17:10 student_model1.h5\n",
            "-rw-r--r-- 1 root root 411M Nov 19 16:33 teacher_model1.h5\n"
          ]
        }
      ],
      "source": [
        "# Investigate the sizes\n",
        "!ls -lh *.h5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model.summary()"
      ],
      "metadata": {
        "id": "9B5qHgo9bx3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a120d658-bc66-4ac7-f836-fa9a4941e8cd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 8)                 107598439 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 107,598,439\n",
            "Trainable params: 89,924,616\n",
            "Non-trainable params: 17,673,823\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.summary()"
      ],
      "metadata": {
        "id": "6tBhcC3ccUGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307d68ac-9a10-40d1-8934-51ed0ae8544f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"student\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 112, 112, 16)      448       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 112, 112, 16)      0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 16)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 56, 56, 32)        4640      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 802824    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 807,912\n",
            "Trainable params: 807,912\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_data_gen():\n",
        "    for input_value in tf.data.Dataset.from_tensor_slices(train_dataset).batch(1).take(100):\n",
        "        yield [input_value]\n",
        "\n",
        "def convert_to_tflite(model, tflite_file):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.representative_dataset = representative_data_gen\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.inference_input_type = tf.int8\n",
        "    converter.inference_output_type = tf.int8\n",
        "    tflite_quant_model = converter.convert()\n",
        "\n",
        "    open(tflite_file, 'wb').write(tflite_quant_model)"
      ],
      "metadata": {
        "id": "2WXpCdSAcUIu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_tflite(teacher_model, \"teacher.tflite\")\n",
        "convert_to_tflite(student_model, \"student.tflite\")"
      ],
      "metadata": {
        "id": "u6D0kE5acULY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5cb80e-062e-4eb5-e077-2d7ffcab5eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh *.tflite"
      ],
      "metadata": {
        "id": "X4Zqs0ULcbiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model.save_weights(\"/content/drive/MyDrive/dataset/teacher.tflite\")\n",
        "student_scratch.save_weights(\"/content/drive/MyDrive/dataset/student.tflite\")"
      ],
      "metadata": {
        "id": "DBK9F2LpcbyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hl_aR1Sucfn3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}